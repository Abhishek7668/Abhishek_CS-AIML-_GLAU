{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Abhishek7668/Abhishek_CS-AIML-_GLAU/blob/main/Text_Generator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dx1AIRmkrPLb"
      },
      "outputs": [],
      "source": [
        "docs=\"\"\"System Flow for Talk to your Knowledge Base (KB) System  User Input:\n",
        "User enters a natural language query about the knowledge base.\n",
        "Preprocessing:\n",
        "Tokenization: Split the user query into tokens (words or subwords).\n",
        "Cleaning: Remove stopwords, punctuation, and perform any necessary text\n",
        "normalization.\n",
        "Query Understanding:\n",
        "Identify the intent of the query (e.g., question type, topic).\n",
        "Extract key entities or keywords that are crucial for finding relevant information\n",
        "in the knowledge base.\n",
        "Knowledge Base Retrieval:\n",
        "Use the identified entities/keywords to retrieve relevant information from the\n",
        "knowledge base.\n",
        "Preprocess the retrieved information (e.g., tokenize, clean).\n",
        "Prompt Generation for LLM:\n",
        "Generate prompts that incorporate the user query and retrieved information to\n",
        "provide context to the LLM.\n",
        "Example Prompt: \"User query: 'What is the capital of France?' Knowledge base\n",
        "excerpt: 'Paris is the capital of France.'\n",
        "Provide additional context and answer based on the knowledge base.\"\n",
        "Response Generation:\n",
        "Utilize the LLM to generate a response based on the provided prompt.\n",
        "Ensure the response is coherent, relevant, and informative.\n",
        "Post-processing:\n",
        "Filter the generated response to ensure it directly addresses the user query.\n",
        "Optionally, perform additional cleaning or formatting of the response for better\n",
        "readability.\n",
        "Output:\n",
        "Present the generated response to the user in a user-friendly format (e.g., text,\n",
        "speech).\n",
        "Prompts for Effective Communication with LLM\n",
        "Prompt for Incorporating User Query:\n",
        "User query: \"What ise the capital of Franc?\"\n",
        "Prompt for Providing Context from Knowledge Base \"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5hz2GwZgftsp",
        "outputId": "a5017459-60c0-4e15-b834-1c4239c36805"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: streamlit in /usr/local/lib/python3.11/dist-packages (1.44.0)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.1.8)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.0.2)\n",
            "Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (24.2)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (11.1.0)\n",
            "Requirement already satisfied: protobuf<6,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.29.4)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (9.0.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.12.2)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.44)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.9.1)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (1.31.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2025.1.31)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.23.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install streamlit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m8s7mPOGr3oH"
      },
      "outputs": [],
      "source": [
        "import streamlit as st\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Eaam4JIBtHm4"
      },
      "outputs": [],
      "source": [
        "tk=Tokenizer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eBKylb36tV9T"
      },
      "outputs": [],
      "source": [
        "tk.fit_on_texts([docs])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qMQo6kv9teF_",
        "outputId": "7c06e9ba-9126-417b-8100-525f5d315662"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'the': 1, 'user': 2, 'query': 3, 'knowledge': 4, 'base': 5, 'for': 6, 'to': 7, 'response': 8, 'of': 9, 'prompt': 10, 'and': 11, 'information': 12, 'llm': 13, 'a': 14, 'or': 15, 'e': 16, 'g': 17, 'relevant': 18, 'context': 19, 'is': 20, 'capital': 21, 'system': 22, 'cleaning': 23, 'perform': 24, 'text': 25, 'entities': 26, 'keywords': 27, 'that': 28, 'in': 29, 'from': 30, 'retrieved': 31, 'generation': 32, 'generate': 33, 'prompts': 34, 'provide': 35, 'france': 36, \"'\": 37, 'additional': 38, 'based': 39, 'on': 40, 'ensure': 41, 'generated': 42, 'flow': 43, 'talk': 44, 'your': 45, 'kb': 46, 'input': 47, 'enters': 48, 'natural': 49, 'language': 50, 'about': 51, 'preprocessing': 52, 'tokenization': 53, 'split': 54, 'into': 55, 'tokens': 56, 'words': 57, 'subwords': 58, 'remove': 59, 'stopwords': 60, 'punctuation': 61, 'any': 62, 'necessary': 63, 'normalization': 64, 'understanding': 65, 'identify': 66, 'intent': 67, 'question': 68, 'type': 69, 'topic': 70, 'extract': 71, 'key': 72, 'are': 73, 'crucial': 74, 'finding': 75, 'retrieval': 76, 'use': 77, 'identified': 78, 'retrieve': 79, 'preprocess': 80, 'tokenize': 81, 'clean': 82, 'incorporate': 83, 'example': 84, \"'what\": 85, 'excerpt': 86, \"'paris\": 87, 'answer': 88, 'utilize': 89, 'provided': 90, 'coherent': 91, 'informative': 92, 'post': 93, 'processing': 94, 'filter': 95, 'it': 96, 'directly': 97, 'addresses': 98, 'optionally': 99, 'formatting': 100, 'better': 101, 'readability': 102, 'output': 103, 'present': 104, 'friendly': 105, 'format': 106, 'speech': 107, 'effective': 108, 'communication': 109, 'with': 110, 'incorporating': 111, 'what': 112, 'ise': 113, 'franc': 114, 'providing': 115}\n"
          ]
        }
      ],
      "source": [
        "print(tk.word_index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J8I0rWiJtssV"
      },
      "outputs": [],
      "source": [
        "input_sequence=[]\n",
        "for sent in docs.split('\\n'):\n",
        "  #print(sent)\n",
        "  #print(tk.texts_to_sequences([sent])[0])\n",
        "    token_sequence=tk.texts_to_sequences([sent])[0]\n",
        "    for i in range(1,len(token_sequence)):\n",
        "        input_sequence.append(token_sequence[ : i+1])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UmUHC9yBur2L",
        "outputId": "fd15c9e1-7194-4b38-a9d8-2cefd74424ef"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[[22, 43],\n",
              " [22, 43, 6],\n",
              " [22, 43, 6, 44],\n",
              " [22, 43, 6, 44, 7],\n",
              " [22, 43, 6, 44, 7, 45],\n",
              " [22, 43, 6, 44, 7, 45, 4],\n",
              " [22, 43, 6, 44, 7, 45, 4, 5],\n",
              " [22, 43, 6, 44, 7, 45, 4, 5, 46],\n",
              " [22, 43, 6, 44, 7, 45, 4, 5, 46, 22],\n",
              " [22, 43, 6, 44, 7, 45, 4, 5, 46, 22, 2],\n",
              " [22, 43, 6, 44, 7, 45, 4, 5, 46, 22, 2, 47],\n",
              " [2, 48],\n",
              " [2, 48, 14],\n",
              " [2, 48, 14, 49],\n",
              " [2, 48, 14, 49, 50],\n",
              " [2, 48, 14, 49, 50, 3],\n",
              " [2, 48, 14, 49, 50, 3, 51],\n",
              " [2, 48, 14, 49, 50, 3, 51, 1],\n",
              " [2, 48, 14, 49, 50, 3, 51, 1, 4],\n",
              " [2, 48, 14, 49, 50, 3, 51, 1, 4, 5],\n",
              " [53, 54],\n",
              " [53, 54, 1],\n",
              " [53, 54, 1, 2],\n",
              " [53, 54, 1, 2, 3],\n",
              " [53, 54, 1, 2, 3, 55],\n",
              " [53, 54, 1, 2, 3, 55, 56],\n",
              " [53, 54, 1, 2, 3, 55, 56, 57],\n",
              " [53, 54, 1, 2, 3, 55, 56, 57, 15],\n",
              " [53, 54, 1, 2, 3, 55, 56, 57, 15, 58],\n",
              " [23, 59],\n",
              " [23, 59, 60],\n",
              " [23, 59, 60, 61],\n",
              " [23, 59, 60, 61, 11],\n",
              " [23, 59, 60, 61, 11, 24],\n",
              " [23, 59, 60, 61, 11, 24, 62],\n",
              " [23, 59, 60, 61, 11, 24, 62, 63],\n",
              " [23, 59, 60, 61, 11, 24, 62, 63, 25],\n",
              " [3, 65],\n",
              " [66, 1],\n",
              " [66, 1, 67],\n",
              " [66, 1, 67, 9],\n",
              " [66, 1, 67, 9, 1],\n",
              " [66, 1, 67, 9, 1, 3],\n",
              " [66, 1, 67, 9, 1, 3, 16],\n",
              " [66, 1, 67, 9, 1, 3, 16, 17],\n",
              " [66, 1, 67, 9, 1, 3, 16, 17, 68],\n",
              " [66, 1, 67, 9, 1, 3, 16, 17, 68, 69],\n",
              " [66, 1, 67, 9, 1, 3, 16, 17, 68, 69, 70],\n",
              " [71, 72],\n",
              " [71, 72, 26],\n",
              " [71, 72, 26, 15],\n",
              " [71, 72, 26, 15, 27],\n",
              " [71, 72, 26, 15, 27, 28],\n",
              " [71, 72, 26, 15, 27, 28, 73],\n",
              " [71, 72, 26, 15, 27, 28, 73, 74],\n",
              " [71, 72, 26, 15, 27, 28, 73, 74, 6],\n",
              " [71, 72, 26, 15, 27, 28, 73, 74, 6, 75],\n",
              " [71, 72, 26, 15, 27, 28, 73, 74, 6, 75, 18],\n",
              " [71, 72, 26, 15, 27, 28, 73, 74, 6, 75, 18, 12],\n",
              " [29, 1],\n",
              " [29, 1, 4],\n",
              " [29, 1, 4, 5],\n",
              " [4, 5],\n",
              " [4, 5, 76],\n",
              " [77, 1],\n",
              " [77, 1, 78],\n",
              " [77, 1, 78, 26],\n",
              " [77, 1, 78, 26, 27],\n",
              " [77, 1, 78, 26, 27, 7],\n",
              " [77, 1, 78, 26, 27, 7, 79],\n",
              " [77, 1, 78, 26, 27, 7, 79, 18],\n",
              " [77, 1, 78, 26, 27, 7, 79, 18, 12],\n",
              " [77, 1, 78, 26, 27, 7, 79, 18, 12, 30],\n",
              " [77, 1, 78, 26, 27, 7, 79, 18, 12, 30, 1],\n",
              " [4, 5],\n",
              " [80, 1],\n",
              " [80, 1, 31],\n",
              " [80, 1, 31, 12],\n",
              " [80, 1, 31, 12, 16],\n",
              " [80, 1, 31, 12, 16, 17],\n",
              " [80, 1, 31, 12, 16, 17, 81],\n",
              " [80, 1, 31, 12, 16, 17, 81, 82],\n",
              " [10, 32],\n",
              " [10, 32, 6],\n",
              " [10, 32, 6, 13],\n",
              " [33, 34],\n",
              " [33, 34, 28],\n",
              " [33, 34, 28, 83],\n",
              " [33, 34, 28, 83, 1],\n",
              " [33, 34, 28, 83, 1, 2],\n",
              " [33, 34, 28, 83, 1, 2, 3],\n",
              " [33, 34, 28, 83, 1, 2, 3, 11],\n",
              " [33, 34, 28, 83, 1, 2, 3, 11, 31],\n",
              " [33, 34, 28, 83, 1, 2, 3, 11, 31, 12],\n",
              " [33, 34, 28, 83, 1, 2, 3, 11, 31, 12, 7],\n",
              " [35, 19],\n",
              " [35, 19, 7],\n",
              " [35, 19, 7, 1],\n",
              " [35, 19, 7, 1, 13],\n",
              " [84, 10],\n",
              " [84, 10, 2],\n",
              " [84, 10, 2, 3],\n",
              " [84, 10, 2, 3, 85],\n",
              " [84, 10, 2, 3, 85, 20],\n",
              " [84, 10, 2, 3, 85, 20, 1],\n",
              " [84, 10, 2, 3, 85, 20, 1, 21],\n",
              " [84, 10, 2, 3, 85, 20, 1, 21, 9],\n",
              " [84, 10, 2, 3, 85, 20, 1, 21, 9, 36],\n",
              " [84, 10, 2, 3, 85, 20, 1, 21, 9, 36, 37],\n",
              " [84, 10, 2, 3, 85, 20, 1, 21, 9, 36, 37, 4],\n",
              " [84, 10, 2, 3, 85, 20, 1, 21, 9, 36, 37, 4, 5],\n",
              " [86, 87],\n",
              " [86, 87, 20],\n",
              " [86, 87, 20, 1],\n",
              " [86, 87, 20, 1, 21],\n",
              " [86, 87, 20, 1, 21, 9],\n",
              " [86, 87, 20, 1, 21, 9, 36],\n",
              " [86, 87, 20, 1, 21, 9, 36, 37],\n",
              " [35, 38],\n",
              " [35, 38, 19],\n",
              " [35, 38, 19, 11],\n",
              " [35, 38, 19, 11, 88],\n",
              " [35, 38, 19, 11, 88, 39],\n",
              " [35, 38, 19, 11, 88, 39, 40],\n",
              " [35, 38, 19, 11, 88, 39, 40, 1],\n",
              " [35, 38, 19, 11, 88, 39, 40, 1, 4],\n",
              " [35, 38, 19, 11, 88, 39, 40, 1, 4, 5],\n",
              " [8, 32],\n",
              " [89, 1],\n",
              " [89, 1, 13],\n",
              " [89, 1, 13, 7],\n",
              " [89, 1, 13, 7, 33],\n",
              " [89, 1, 13, 7, 33, 14],\n",
              " [89, 1, 13, 7, 33, 14, 8],\n",
              " [89, 1, 13, 7, 33, 14, 8, 39],\n",
              " [89, 1, 13, 7, 33, 14, 8, 39, 40],\n",
              " [89, 1, 13, 7, 33, 14, 8, 39, 40, 1],\n",
              " [89, 1, 13, 7, 33, 14, 8, 39, 40, 1, 90],\n",
              " [89, 1, 13, 7, 33, 14, 8, 39, 40, 1, 90, 10],\n",
              " [41, 1],\n",
              " [41, 1, 8],\n",
              " [41, 1, 8, 20],\n",
              " [41, 1, 8, 20, 91],\n",
              " [41, 1, 8, 20, 91, 18],\n",
              " [41, 1, 8, 20, 91, 18, 11],\n",
              " [41, 1, 8, 20, 91, 18, 11, 92],\n",
              " [93, 94],\n",
              " [95, 1],\n",
              " [95, 1, 42],\n",
              " [95, 1, 42, 8],\n",
              " [95, 1, 42, 8, 7],\n",
              " [95, 1, 42, 8, 7, 41],\n",
              " [95, 1, 42, 8, 7, 41, 96],\n",
              " [95, 1, 42, 8, 7, 41, 96, 97],\n",
              " [95, 1, 42, 8, 7, 41, 96, 97, 98],\n",
              " [95, 1, 42, 8, 7, 41, 96, 97, 98, 1],\n",
              " [95, 1, 42, 8, 7, 41, 96, 97, 98, 1, 2],\n",
              " [95, 1, 42, 8, 7, 41, 96, 97, 98, 1, 2, 3],\n",
              " [99, 24],\n",
              " [99, 24, 38],\n",
              " [99, 24, 38, 23],\n",
              " [99, 24, 38, 23, 15],\n",
              " [99, 24, 38, 23, 15, 100],\n",
              " [99, 24, 38, 23, 15, 100, 9],\n",
              " [99, 24, 38, 23, 15, 100, 9, 1],\n",
              " [99, 24, 38, 23, 15, 100, 9, 1, 8],\n",
              " [99, 24, 38, 23, 15, 100, 9, 1, 8, 6],\n",
              " [99, 24, 38, 23, 15, 100, 9, 1, 8, 6, 101],\n",
              " [104, 1],\n",
              " [104, 1, 42],\n",
              " [104, 1, 42, 8],\n",
              " [104, 1, 42, 8, 7],\n",
              " [104, 1, 42, 8, 7, 1],\n",
              " [104, 1, 42, 8, 7, 1, 2],\n",
              " [104, 1, 42, 8, 7, 1, 2, 29],\n",
              " [104, 1, 42, 8, 7, 1, 2, 29, 14],\n",
              " [104, 1, 42, 8, 7, 1, 2, 29, 14, 2],\n",
              " [104, 1, 42, 8, 7, 1, 2, 29, 14, 2, 105],\n",
              " [104, 1, 42, 8, 7, 1, 2, 29, 14, 2, 105, 106],\n",
              " [104, 1, 42, 8, 7, 1, 2, 29, 14, 2, 105, 106, 16],\n",
              " [104, 1, 42, 8, 7, 1, 2, 29, 14, 2, 105, 106, 16, 17],\n",
              " [104, 1, 42, 8, 7, 1, 2, 29, 14, 2, 105, 106, 16, 17, 25],\n",
              " [34, 6],\n",
              " [34, 6, 108],\n",
              " [34, 6, 108, 109],\n",
              " [34, 6, 108, 109, 110],\n",
              " [34, 6, 108, 109, 110, 13],\n",
              " [10, 6],\n",
              " [10, 6, 111],\n",
              " [10, 6, 111, 2],\n",
              " [10, 6, 111, 2, 3],\n",
              " [2, 3],\n",
              " [2, 3, 112],\n",
              " [2, 3, 112, 113],\n",
              " [2, 3, 112, 113, 1],\n",
              " [2, 3, 112, 113, 1, 21],\n",
              " [2, 3, 112, 113, 1, 21, 9],\n",
              " [2, 3, 112, 113, 1, 21, 9, 114],\n",
              " [10, 6],\n",
              " [10, 6, 115],\n",
              " [10, 6, 115, 19],\n",
              " [10, 6, 115, 19, 30],\n",
              " [10, 6, 115, 19, 30, 4],\n",
              " [10, 6, 115, 19, 30, 4, 5]]"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "input_sequence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P39WJewvw6y3",
        "outputId": "b5d5eef3-d908-424c-acc3-9767f2286dc8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "15"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "m=(max([len(x) for x in input_sequence]))\n",
        "m"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mVPxHy7xx4AC",
        "outputId": "818ac4cf-aa0a-4979-b12d-99f0fd9cebe3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[  0,   0,   0, ...,   0,  22,  43],\n",
              "       [  0,   0,   0, ...,  22,  43,   6],\n",
              "       [  0,   0,   0, ...,  43,   6,  44],\n",
              "       ...,\n",
              "       [  0,   0,   0, ..., 115,  19,  30],\n",
              "       [  0,   0,   0, ...,  19,  30,   4],\n",
              "       [  0,   0,   0, ...,  30,   4,   5]], dtype=int32)"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "pad=pad_sequences(input_sequence,maxlen=m,padding='pre')\n",
        "pad\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c5Q2_XodyOmH",
        "outputId": "ca843af0-ff65-4b30-cfe4-df2dc6043925"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(204, 14)"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x=pad[:,:-1] # input\n",
        "x.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P7e2eSw4E93i",
        "outputId": "30b86e07-023a-4de1-e66a-76cb23ee4b97"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(204,)"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y=pad[:,-1] #output\n",
        "y.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_3fZQojNFW-l",
        "outputId": "9fc3b396-65d9-4353-82a9-5c89efb91ab4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(204, 116)"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "y=to_categorical(y,num_classes=len(tk.word_index)+1)\n",
        "y.shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8LkycLI_ICLl"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding,LSTM,Dense\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E_J3KqKDIUTu",
        "outputId": "8f64df66-6a20-4799-b10f-647ad39558be"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "model=Sequential()\n",
        "model.add(Embedding(116,100,input_length=15))#116 Empeding layer ,#100 out dimention of theembedding vactor\n",
        "model.add(LSTM(150))\n",
        "model.add(Dense(116,activation='softmax'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nGQFWYaTLziL"
      },
      "outputs": [],
      "source": [
        "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J51XOZ9xNN_L",
        "outputId": "37cb9e4a-378c-44e7-d8ba-3e77d35b3e55"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 33ms/step - accuracy: 0.0533 - loss: 4.7450\n",
            "Epoch 2/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.1209 - loss: 4.6397\n",
            "Epoch 3/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.1173 - loss: 4.3462\n",
            "Epoch 4/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.0788 - loss: 4.3559\n",
            "Epoch 5/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.1013 - loss: 4.2411\n",
            "Epoch 6/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - accuracy: 0.1202 - loss: 4.1782\n",
            "Epoch 7/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.0915 - loss: 4.2183\n",
            "Epoch 8/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.0877 - loss: 4.1511\n",
            "Epoch 9/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.1209 - loss: 4.0582\n",
            "Epoch 10/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.0988 - loss: 4.1134\n",
            "Epoch 11/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.1158 - loss: 3.9613\n",
            "Epoch 12/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - accuracy: 0.1173 - loss: 3.9638\n",
            "Epoch 13/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - accuracy: 0.1453 - loss: 3.8243\n",
            "Epoch 14/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - accuracy: 0.1341 - loss: 3.7907\n",
            "Epoch 15/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - accuracy: 0.1683 - loss: 3.7040\n",
            "Epoch 16/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.2055 - loss: 3.5689\n",
            "Epoch 17/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 138ms/step - accuracy: 0.1775 - loss: 3.5097\n",
            "Epoch 18/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 177ms/step - accuracy: 0.1883 - loss: 3.4730\n",
            "Epoch 19/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - accuracy: 0.2398 - loss: 3.3480\n",
            "Epoch 20/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 128ms/step - accuracy: 0.2035 - loss: 3.2982\n",
            "Epoch 21/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 113ms/step - accuracy: 0.2277 - loss: 3.2105\n",
            "Epoch 22/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - accuracy: 0.2584 - loss: 3.1027\n",
            "Epoch 23/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - accuracy: 0.2591 - loss: 2.9410\n",
            "Epoch 24/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - accuracy: 0.3372 - loss: 2.8178\n",
            "Epoch 25/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - accuracy: 0.3382 - loss: 2.7471\n",
            "Epoch 26/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - accuracy: 0.3890 - loss: 2.6621\n",
            "Epoch 27/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.3825 - loss: 2.5136\n",
            "Epoch 28/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.4524 - loss: 2.3572\n",
            "Epoch 29/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 0.4757 - loss: 2.3513\n",
            "Epoch 30/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - accuracy: 0.4719 - loss: 2.1624\n",
            "Epoch 31/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - accuracy: 0.4559 - loss: 2.0839\n",
            "Epoch 32/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - accuracy: 0.4563 - loss: 2.0393\n",
            "Epoch 33/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - accuracy: 0.5511 - loss: 1.9542\n",
            "Epoch 34/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.5579 - loss: 1.7931\n",
            "Epoch 35/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6139 - loss: 1.6916\n",
            "Epoch 36/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.5871 - loss: 1.6380\n",
            "Epoch 37/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.6183 - loss: 1.6176\n",
            "Epoch 38/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.6979 - loss: 1.4475\n",
            "Epoch 39/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.6857 - loss: 1.3960\n",
            "Epoch 40/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7219 - loss: 1.3790\n",
            "Epoch 41/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7311 - loss: 1.2949\n",
            "Epoch 42/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7617 - loss: 1.2567\n",
            "Epoch 43/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8095 - loss: 1.1251\n",
            "Epoch 44/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.8137 - loss: 1.1268\n",
            "Epoch 45/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.8536 - loss: 1.0637\n",
            "Epoch 46/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 0.8690 - loss: 0.9754\n",
            "Epoch 47/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.8341 - loss: 0.9882\n",
            "Epoch 48/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 0.8737 - loss: 0.9355\n",
            "Epoch 49/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 0.8637 - loss: 0.9144\n",
            "Epoch 50/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - accuracy: 0.8851 - loss: 0.8393\n",
            "Epoch 51/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.9017 - loss: 0.7687\n",
            "Epoch 52/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.9253 - loss: 0.7317\n",
            "Epoch 53/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9238 - loss: 0.7088\n",
            "Epoch 54/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9259 - loss: 0.7206\n",
            "Epoch 55/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9332 - loss: 0.6479\n",
            "Epoch 56/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9371 - loss: 0.6761\n",
            "Epoch 57/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9445 - loss: 0.6177\n",
            "Epoch 58/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9357 - loss: 0.6392\n",
            "Epoch 59/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9515 - loss: 0.5497\n",
            "Epoch 60/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9662 - loss: 0.5455\n",
            "Epoch 61/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9672 - loss: 0.5308\n",
            "Epoch 62/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9510 - loss: 0.5324\n",
            "Epoch 63/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9628 - loss: 0.4857\n",
            "Epoch 64/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9671 - loss: 0.4682\n",
            "Epoch 65/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9649 - loss: 0.4520\n",
            "Epoch 66/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9811 - loss: 0.4034\n",
            "Epoch 67/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9723 - loss: 0.4032\n",
            "Epoch 68/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9678 - loss: 0.3939\n",
            "Epoch 69/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9841 - loss: 0.3626\n",
            "Epoch 70/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9902 - loss: 0.3882\n",
            "Epoch 71/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9698 - loss: 0.3646\n",
            "Epoch 72/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9671 - loss: 0.3531\n",
            "Epoch 73/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9740 - loss: 0.3358\n",
            "Epoch 74/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9850 - loss: 0.3017\n",
            "Epoch 75/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9828 - loss: 0.2975\n",
            "Epoch 76/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9807 - loss: 0.2944\n",
            "Epoch 77/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9685 - loss: 0.3091\n",
            "Epoch 78/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9725 - loss: 0.2827\n",
            "Epoch 79/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9828 - loss: 0.2710\n",
            "Epoch 80/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9856 - loss: 0.2694\n",
            "Epoch 81/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9696 - loss: 0.2614\n",
            "Epoch 82/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9838 - loss: 0.2387\n",
            "Epoch 83/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9869 - loss: 0.2383\n",
            "Epoch 84/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9810 - loss: 0.2224\n",
            "Epoch 85/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9909 - loss: 0.2041\n",
            "Epoch 86/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9748 - loss: 0.2178\n",
            "Epoch 87/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9869 - loss: 0.2132\n",
            "Epoch 88/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9747 - loss: 0.2071\n",
            "Epoch 89/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 0.9597 - loss: 0.2188\n",
            "Epoch 90/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.9900 - loss: 0.1834\n",
            "Epoch 91/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.9757 - loss: 0.1878\n",
            "Epoch 92/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.9689 - loss: 0.1861\n",
            "Epoch 93/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.9739 - loss: 0.1884\n",
            "Epoch 94/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.9807 - loss: 0.1831\n",
            "Epoch 95/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 0.9734 - loss: 0.1679\n",
            "Epoch 96/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.9907 - loss: 0.1722\n",
            "Epoch 97/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9831 - loss: 0.1612\n",
            "Epoch 98/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9820 - loss: 0.1451\n",
            "Epoch 99/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9790 - loss: 0.1570\n",
            "Epoch 100/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9807 - loss: 0.1574\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7a50d340c750>"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(x,y ,epochs=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n9Vdyx94Cn66",
        "outputId": "7c1dcf47-edc9-41bb-973d-82b9ff609291"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ],
      "source": [
        "model.save(\"Text_Generator.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jVXk9nUwBruC",
        "outputId": "c2946ef4-1bd6-41c2-e6e5-fc0b1cd40ad8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['.config', 'drive', 'next_word_generator.py', 'Text_Generator.h5', 'sample_data']\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "print(os.listdir())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eWbx_Fp2Pdlo",
        "outputId": "977aceeb-d7b4-489c-9aaa-d9ea583438bb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-03-31 12:26:36.829 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-03-31 12:26:37.520 \n",
            "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
            "  command:\n",
            "\n",
            "    streamlit run /usr/local/lib/python3.11/dist-packages/colab_kernel_launcher.py [ARGUMENTS]\n",
            "2025-03-31 12:26:37.524 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 546ms/step\n",
            "Effective the\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "Effective the llm\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
            "Effective the llm to\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
            "Effective the llm to the\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
            "Effective the llm to the llm\n"
          ]
        }
      ],
      "source": [
        "\n",
        "st.title(\"Next Word Generator Model\")\n",
        "import time\n",
        "text=\"Effective\"\n",
        "for i in range(5):\n",
        "  #tokenizer\n",
        "  tokens=tk.texts_to_sequences([text])[0]\n",
        "  tokens\n",
        "  #padding\n",
        "  pading=pad_sequences([tokens],maxlen=m,padding='pre')\n",
        "  #predit\n",
        "  pos= np.argmax(model.predict(pading))\n",
        "  for word,index in tk.word_index.items():\n",
        "     if index==pos:\n",
        "      text=text+' '+word\n",
        "      break\n",
        "  print(text)\n",
        "  time.sleep(1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pfq9DlJtSNqL",
        "outputId": "56283222-2dc5-40dd-f6be-5b9e8fb562e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Usage: streamlit run [OPTIONS] TARGET [ARGS]...\n",
            "Try 'streamlit run --help' for help.\n",
            "\n",
            "Error: Invalid value: File does not exist: main.py\n",
            "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K\u001b[1G\u001b[0JNeed to install the following packages:\n",
            "localtunnel@2.0.2\n",
            "Ok to proceed? (y) \u001b[20G^C\n"
          ]
        }
      ],
      "source": [
        "!streamlit run main.py & npx localtunnel --port 8501\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CzYWCcUEE_am",
        "outputId": "faa43f37-d80a-4253-d7a6-300c78c75476"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: streamlit in /usr/local/lib/python3.11/dist-packages (1.44.0)\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement localtunnel (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for localtunnel\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install streamlit localtunnel\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CedGOif2FPSd",
        "outputId": "e76bef76-2884-4e91-d02c-669693b107d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9As2k5OqGR40"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "liUX8HX-F1kY"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9rIxknj6DMIq",
        "outputId": "566ace66-cf5c-488a-d7fb-574429319f92"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting next_word_generator.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile next_word_generator.py\n",
        "import streamlit as st\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import time\n",
        "import pickle\n",
        "\n",
        "# Load trained model\n",
        "model = tf.keras.models.load_model(\"Text_generator.h5\")  # Ensure this file is available\n",
        "\n",
        "# Load Tokenizer\n",
        "with open(\"tokenizer.pkl\", \"rb\") as handle:\n",
        "    tk = pickle.load(handle)\n",
        "\n",
        "m = 10  # Max sequence length\n",
        "\n",
        "st.title(\"Next Word Generator Model\")\n",
        "text_input = st.text_input(\"Enter a starting word:\", \"Effective\")\n",
        "num_words = st.slider(\"Number of words to generate:\", 1, 20, 5)\n",
        "\n",
        "if st.button(\"Generate Text\"):\n",
        "    text = text_input\n",
        "    for i in range(num_words):\n",
        "        tokens = tk.texts_to_sequences([text])[0]\n",
        "        padding = pad_sequences([tokens], maxlen=m, padding='pre')\n",
        "        pos = np.argmax(model.predict(padding))\n",
        "        for word, index in tk.word_index.items():\n",
        "            if index == pos:\n",
        "                text += ' ' + word\n",
        "                break\n",
        "        time.sleep(0.5)\n",
        "    st.write(\"Generated Text:\", text)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GWZJHuwEJcga",
        "outputId": "de2d5c78-dd90-4b4a-eb8a-5047bbe7f001"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "kill: usage: kill [-s sigspec | -n signum | -sigspec] pid | jobspec ... or kill -l [sigspec]\n"
          ]
        }
      ],
      "source": [
        "!kill $(lsof -t -i:8501)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "JdunSLh6IwYl",
        "outputId": "64f2341c-1c94-443f-c42e-45571ffc8f15"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.168.100.177:8501\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0Kyour url is: https://purple-keys-walk.loca.lt\n"
          ]
        }
      ],
      "source": [
        "!streamlit run next_word_generator.py & npx localtunnel --port 8501"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "11QLmsvrIHR1hqY1e5a48M9VDUBoH5qmB",
      "authorship_tag": "ABX9TyNn3g2DVPWSOUMI2wCiwQau",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}